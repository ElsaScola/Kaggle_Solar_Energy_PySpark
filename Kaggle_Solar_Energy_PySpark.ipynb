{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Intelligence: Methods and Technologies\n",
    "\n",
    "# Assignment 3: PySpark Assignment\n",
    "## Authors:  Liana Mehrabyan and Elsa Scola Martín\n",
    "### Objective:\n",
    "Given a dataset from the Kaggle competition ”[AMS 2013-2014 Solar Energy Prediction Contest](https://www.kaggle.com/c/ams-2014-solar-energy-prediction-contest/)” the goal of this assignment is to use  meteorological  variables  forecasted  by GFS as input  attributes  to  a machine learning model that is able to estimate how much solar energy is going to be produced at one of the solar plants in Oklahoma.\n",
    "\n",
    "To solve this problem we focus in using PySpark in Databricks along with some techinques seen in class, like Pipelines.\n",
    "\n",
    "\n",
    "### What is done in the Notebook: \n",
    "- Load the data.\n",
    "- Split the train data in train and validation.\n",
    "- Structure the data.\n",
    "- Explore k values.\n",
    "- Evaluate the results by plotting MAE for each k components.\n",
    "- Put together train and validation sets.\n",
    "- Final Linear Regressor with k=4.\n",
    "- Perform Linear Regression on all the 1200 PCA components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import matplotlib\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sd = spark.read.csv(path='/FileStore/tables/trainst1ns16.csv', header=True, inferSchema=True)\n",
    "test_sd = spark.read.csv(path='/FileStore/tables/testst1ns16.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide train partition in train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_sd  = train_sd.filter(train_sd['counter']>=3650)\n",
    "train_sd = train_sd.filter(train_sd['counter']<3650)\n",
    "train_sd = train_sd.drop('counter')\n",
    "validation_sd = validation_sd.drop('counter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ignore = ['energy']\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[x for x in train_sd.columns if x not in ignore],\n",
    "    outputCol='features')\n",
    "\n",
    "train_sd_new = assembler.transform(train_sd).select(['energy', 'features'])\n",
    "validation_sd_new = assembler.transform(validation_sd).select(['energy', 'features'])\n",
    "test_df = assembler.transform(test_sd).select(['energy', 'features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_mae = []\n",
    "for i in range (1,21):\n",
    "  scaler1 = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=False, withMean=True)\n",
    "  pca1 = PCA(k=i, inputCol=\"scaledFeatures\")\n",
    "  lr = LinearRegression(featuresCol = pca1.getOutputCol(), labelCol='energy')\n",
    "  pipeline1 = Pipeline(stages=[scaler1, pca1, lr])\n",
    "  \n",
    "  model1 = pipeline1.fit(train_sd_new)\n",
    "  predictions = model1.transform(validation_sd_new)\n",
    "\n",
    "  evaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "  mae1 = evaluator.evaluate(predictions)\n",
    "  results_mae.append(mae1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MAE for each k components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()# k components\n",
    "x = list(range(len(results_mae)))\n",
    "# plotting the points  \n",
    "plt.plot(x, results_mae) \n",
    "plt.xlabel('k components') \n",
    "plt.ylabel('MAE') \n",
    "plt.title('MAE value for each k components') \n",
    "fig=plt.subplot()\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen in the plot the optimal number of components is around 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put together train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">(4380, 2)\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = train_sd_new.union(validation_sd_new)\n",
    "print((train_df.count(), len(train_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final linear regressor (k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spark does not center the data. Let's do that with a StandardScaler:\n",
    "scaler1 = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=False, withMean=True)\n",
    "pca1 = PCA(k=4, inputCol=\"scaledFeatures\")\n",
    "\n",
    "lr = LinearRegression(featuresCol = pca1.getOutputCol(), labelCol='energy')\n",
    "\n",
    "pipeline1 = Pipeline(stages=[scaler1, pca1, lr])\n",
    "\n",
    "model1 = pipeline1.fit(train_df)\n",
    "predictions = model1.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae1 = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">2452790.1503722304\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(mae1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on all the 1200 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "scaler1 = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=False, withMean=True)\n",
    "pca1 = PCA(k=1200, inputCol=\"scaledFeatures\")\n",
    "\n",
    "lr = LinearRegression(featuresCol = pca1.getOutputCol(), labelCol='energy')\n",
    "\n",
    "pipeline1 = Pipeline(stages=[scaler1, pca1, lr])\n",
    "\n",
    "model1 = pipeline1.fit(train_df)\n",
    "predictions = model1.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae1 = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">2669224.5896751187\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(mae1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen we get a higher error by using all of the principal components. This shows that there is some redundancy in the input attributes that can be removed via PCA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "name": "spark_ml_v2",
  "notebookId": 3914260502281082
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
